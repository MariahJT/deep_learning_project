{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "cycleGAN_MNIST2USPS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEIl2OGEKMEZ",
        "colab_type": "text"
      },
      "source": [
        "#**CycleGAN applying to MNIST2USPS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzVjhDg0KMEb",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we are going to implement the CycleGAN architecture for the dataset MNIST to the dataset USPS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWAPg0LNKMEb",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "RRVYF5iOKMEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################\n",
        "#  SETUP PYTHON ENVIRONMENT  #  \n",
        "##############################\n",
        "\n",
        "!pip install torch torchvision\n",
        "conda update pytorch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq8piX297JIr",
        "colab_type": "code",
        "outputId": "8553479c-61dc-4097-b163-78f3afc7f820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!wget -c https://github.com/YannickLy/DeepLearning-Project-ENSAE-2020/blob/master/Data/usps.h5?raw=true -O usps.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-11 18:33:08--  https://github.com/YannickLy/DeepLearning-Project-ENSAE-2020/blob/master/Data/usps.h5?raw=true\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/YannickLy/DeepLearning-Project-ENSAE-2020/raw/master/Data/usps.h5 [following]\n",
            "--2020-05-11 18:33:08--  https://github.com/YannickLy/DeepLearning-Project-ENSAE-2020/raw/master/Data/usps.h5\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/YannickLy/DeepLearning-Project-ENSAE-2020/master/Data/usps.h5 [following]\n",
            "--2020-05-11 18:33:08--  https://raw.githubusercontent.com/YannickLy/DeepLearning-Project-ENSAE-2020/master/Data/usps.h5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2913522 (2.8M) [application/octet-stream]\n",
            "Saving to: ‘usps.h5’\n",
            "\n",
            "usps.h5             100%[===================>]   2.78M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-05-11 18:33:09 (22.7 MB/s) - ‘usps.h5’ saved [2913522/2913522]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8IR9BFnKMEi",
        "colab_type": "text"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lokzAf0DKMEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def init_normal_weights(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        if hasattr(m, \"bias\") and m.bias is not None:\n",
        "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "def print_models(G_XtoY, G_YtoX, D_X, D_Y):\n",
        "    \n",
        "    \"\"\" Prints model information for the generators and discriminators. \"\"\"\n",
        "    \n",
        "    print(\"                 G_XtoY                \")\n",
        "    print(\"---------------------------------------\")\n",
        "    print(G_XtoY)\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    print(\"                 G_YtoX                \")\n",
        "    print(\"---------------------------------------\")\n",
        "    print(G_YtoX)\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    print(\"                  D_X                  \")\n",
        "    print(\"---------------------------------------\")\n",
        "    print(D_X)\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    print(\"                  D_Y                  \")\n",
        "    print(\"---------------------------------------\")\n",
        "    print(D_Y)\n",
        "    print(\"---------------------------------------\")\n",
        "      \n",
        "class LambdaLR:\n",
        "    \n",
        "    \"\"\" LambdaLR or LambdaLearningRate\n",
        "        Allow us to decrease the learning rate from a specific epoch ('decay_start_epoch').\n",
        "        This accelerates learning and become and allows to be more precise for larger epochs.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "        self.n_epochs = n_epochs\n",
        "        self.offset = offset\n",
        "        self.decay_start_epoch = decay_start_epoch\n",
        "        \n",
        "    def step(self, epoch):\n",
        "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)\n",
        "\n",
        "class MergedDataset(Dataset):\n",
        "    \n",
        "    \"\"\" MergedDataSet\n",
        "        Allow us to convert grayscale images into 3 channel RGB images.\n",
        "        And merges two datasets of different styles into one dataset.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, dataset_X, dataset_Y, transforms_):\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "        self.dataset_X = dataset_X\n",
        "        self.dataset_Y = dataset_Y\n",
        "        \n",
        "    def __to_rgb(self, image):\n",
        "        trans = transforms.ToPILImage()\n",
        "        pil_img = trans(image)\n",
        "        rgb_image = Image.new(\"RGB\", pil_img.size)\n",
        "        rgb_image.paste(pil_img)\n",
        "        return rgb_image\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_X = self.dataset_X[index % len(self.dataset_X)][0]\n",
        "        image_Y = self.dataset_Y[index % len(self.dataset_Y)][0]\n",
        "        # Convert grayscale images to rgb\n",
        "        image_X = self.__to_rgb(image_X)\n",
        "        image_Y = self.__to_rgb(image_Y)\n",
        "        item_X = self.transform(image_X)\n",
        "        item_Y = self.transform(image_Y)\n",
        "        return {\"X\": item_X, \"Y\": item_Y}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return max(len(self.dataset_X), len(self.dataset_Y))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S_8z9YRKMEl",
        "colab_type": "text"
      },
      "source": [
        "## Architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNcrN4LrKMEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    \n",
        "    \"\"\"Defines the architecture of a ResidualBlock\n",
        "       Note: We decided to choose the number of ResidualBlock we would like to put in both generators\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, in_features):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    \"\"\"Defines the architecture of the generator network.\n",
        "       Note: Both generators G_XtoY and G_YtoX have the same architecture in this assignment.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, opt):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Initial convolution block (first convolutional layer)\n",
        "        out_features = 64\n",
        "        model = [\n",
        "            # Pads the input tensor using the reflection of the input boundary\n",
        "            nn.ReflectionPad2d(opt.channels),\n",
        "            nn.Conv2d(opt.channels, out_features, 7),\n",
        "            # Applies Instance Normalization over a 4D input\n",
        "            nn.InstanceNorm2d(out_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        in_features = out_features\n",
        "\n",
        "        # Two convolution blocks for downsampling\n",
        "        for _ in range(2):\n",
        "            out_features *= 2\n",
        "            model += [\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_features = out_features\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(opt.n_residual_blocks):\n",
        "            model += [ResnetBlock(out_features)]\n",
        "\n",
        "        # Two convolution blocks for upsampling\n",
        "        for _ in range(2):\n",
        "            out_features //= 2\n",
        "            model += [\n",
        "                # Upsamples a given multi-channel data. Double the spatial space.\n",
        "                nn.Upsample(scale_factor=2),\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_features = out_features\n",
        "\n",
        "        # Output layer\n",
        "        model += [nn.ReflectionPad2d(opt.channels), nn.Conv2d(out_features, opt.channels, 7), nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \n",
        "    \"\"\"Defines the architecture of the discriminator network.\n",
        "       Note: Both discriminators D_X and D_Y have the same architecture in this assignment.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, opt):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Calculate output shape of image discriminator\n",
        "        self.output_shape = (1, opt.img_size // 2 ** 4, opt.img_size // 2 ** 4)\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalize = True):\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride = 2, padding = 1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace = True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 64, normalize = False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(512, 1, 4, padding = 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69ySO7NX6W2k",
        "colab_type": "text"
      },
      "source": [
        "## CycleGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNAZQxL86dx3",
        "colab_type": "code",
        "outputId": "ef995f80-8b3a-497d-9fd1-b79e3110247d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "import itertools\n",
        "import argparse\n",
        "import h5py\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "\n",
        "##############################\n",
        "#    MODEL CONFIGURATION     # \n",
        "##############################\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "# data set\n",
        "parser.add_argument(\"--dataset_name\", type=str, default=\"MNIST2USPS\", help=\"name of the dataset\")\n",
        "parser.add_argument(\"--img_size\", type=int, default=16, help=\"size of each image dimension\")\n",
        "parser.add_argument(\"--channels\", type=int, default=3, help=\"number of image channels\")\n",
        "# cycleGAN parameters\n",
        "parser.add_argument(\"--n_residual_blocks\", type=int, default=1, help=\"number of residual blocks in generator\")\n",
        "parser.add_argument(\"--lambda_cyc\", type=float, default=10.0, help=\"cycle loss weight\")\n",
        "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
        "parser.add_argument(\"--b1\", type=float, default=0.3, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--decay_epoch\", type=int, default=10, help=\"epoch from which to start lr decay\")\n",
        "# training parameters\n",
        "parser.add_argument(\"--cuda\", type=bool, default=False, help=\"change to GPU mode\")\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=50, help = \"number of epochs of training\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=32, help=\"size of the batches\")\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=0, help=\"number of cpu threads to use during batch generation\") # 0 by default in windows because multiprocessing doesn't work\n",
        "# saving parameters\n",
        "parser.add_argument(\"--epoch\", type=int, default=0, help = \"epoch to start training from\")\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=1000, help=\"interval between saving generator outputs\")\n",
        "parser.add_argument(\"--checkpoint_interval\", type=int, default=1, help=\"interval between saving model checkpoints\")\n",
        "opt = parser.parse_args(\"\")\n",
        "\n",
        "# GPU option\n",
        "cuda = torch.cuda.is_available()\n",
        "if cuda:\n",
        "    print('Models moved to GPU.')\n",
        "    opt.cuda = True\n",
        "\n",
        "# Create sample image, checkpoint and losses directories\n",
        "os.makedirs(\"images\", exist_ok = True)\n",
        "os.makedirs(\"saved_models\", exist_ok = True)\n",
        "os.makedirs(\"losses_models\", exist_ok = True)\n",
        "\n",
        "# Image transformations\n",
        "transforms_ = [\n",
        "    transforms.Resize(int(opt.img_size), Image.BICUBIC),\n",
        "    # Add some noise into the data\n",
        "    transforms.RandomCrop((opt.img_size, opt.img_size)),\n",
        "    transforms.ToTensor(),\n",
        "]\n",
        "\n",
        "# MNIST datasets\n",
        "MNIST_trainset = datasets.MNIST('MNIST',\n",
        "                                train = True, \n",
        "                                download = True,\n",
        "                                transform = transforms.Compose([transforms.Resize(opt.img_size), transforms.ToTensor()]))\n",
        "MNIST_testset = datasets.MNIST('MNIST',\n",
        "                               train = False,\n",
        "                               download = True,\n",
        "                               transform = transforms.Compose([transforms.Resize(opt.img_size), transforms.ToTensor()]))\n",
        "\n",
        "# USPS dataset\n",
        "with h5py.File('usps.h5', 'r') as hf:\n",
        "    train = hf.get('train')\n",
        "    X_train = train.get('data')[:]\n",
        "    test = hf.get('test')\n",
        "    X_test = test.get('data')[:]\n",
        "\n",
        "# The data were in an 1D numpy array of grayscale and normalised between [0,1]\n",
        "# We transform the data into the same dimensions as for the mnist.\n",
        "X_train = X_train.reshape(-1, 1, 16, 16) \n",
        "X_test = X_test.reshape(-1, 1, 16, 16) \n",
        "\n",
        "USPS_trainset = data.TensorDataset(torch.Tensor(X_train))\n",
        "USPS_testset = data.TensorDataset(torch.Tensor(X_test))\n",
        "\n",
        "# Train dataloader\n",
        "train_dataloader = DataLoader(\n",
        "    MergedDataset(MNIST_trainset, USPS_trainset, transforms_ = transforms_),\n",
        "    batch_size = opt.batch_size,\n",
        "    shuffle = True,\n",
        "    num_workers = opt.n_cpu,\n",
        ")\n",
        "\n",
        "# Test dataloader\n",
        "test_dataloader = DataLoader(\n",
        "    MergedDataset(MNIST_testset, USPS_testset, transforms_ = transforms_),\n",
        "    batch_size = 5,\n",
        "    shuffle = True,\n",
        "    num_workers = opt.n_cpu,\n",
        ")\n",
        "\n",
        "##############################\n",
        "#    MODEL INITIALIZATION    # \n",
        "##############################\n",
        "\n",
        "def create_model(opt):\n",
        "    \n",
        "    \"\"\" Builds the generators and discriminators. \"\"\"\n",
        "    \n",
        "    # Initialize generator and discriminator\n",
        "    G_XtoY = Generator(input_shape, opt.n_residual_blocks)\n",
        "    G_YtoX = Generator(input_shape, opt.n_residual_blocks)\n",
        "    D_X = Discriminator(input_shape)\n",
        "    D_Y = Discriminator(input_shape)\n",
        "    \n",
        "    print_models(G_XtoY, G_YtoX, D_X, D_Y)\n",
        "    \n",
        "    if opt.cuda:\n",
        "        G_XtoY = G_XtoY.cuda()\n",
        "        G_YtoX = G_YtoX.cuda()\n",
        "        D_X = D_X.cuda()\n",
        "        D_Y = D_Y.cuda()\n",
        "        \n",
        "    if opt.epoch != 0:\n",
        "        # Load pretrained models\n",
        "        G_XtoY.load_state_dict(torch.load(\"saved_models/G_XtoY_%d.pth\" % opt.epoch))\n",
        "        G_YtoX.load_state_dict(torch.load(\"saved_models/G_YtoX_%d.pth\" % opt.epoch))\n",
        "        D_X.load_state_dict(torch.load(\"saved_models/D_X_%d.pth\" % opt.epoch))\n",
        "        D_Y.load_state_dict(torch.load(\"saved_models/D_Y_%d.pth\" % opt.epoch))\n",
        "    else:\n",
        "        # Initialize weights\n",
        "        G_XtoY.apply(init_normal_weights)\n",
        "        G_YtoX.apply(init_normal_weights)\n",
        "        D_X.apply(init_normal_weights)\n",
        "        D_Y.apply(init_normal_weights)\n",
        "        \n",
        "    return G_XtoY, G_YtoX, D_X, D_Y\n",
        "      \n",
        "##############################\n",
        "#       MODEL TRAINING       # \n",
        "##############################\n",
        "    \n",
        "def training_loop(train_dataloader, test_dataloader, opt):\n",
        "    \n",
        "    \"\"\" Runs the training loop.\n",
        "        * Saves checkpoint every opt.checkpoint_interval iterations\n",
        "        * Saves generated samples every opt.sample_interval iterations\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create generators and discriminators\n",
        "    G_XtoY, G_YtoX, D_X, D_Y = create_model(opt)\n",
        "    \n",
        "    # Losses\n",
        "    loss_GAN = torch.nn.MSELoss()\n",
        "    loss_cycle = torch.nn.L1Loss()\n",
        "\n",
        "    # Optimizers\n",
        "    optimizer_G = torch.optim.Adam(itertools.chain(G_XtoY.parameters(), G_YtoX.parameters()), lr = opt.lr, betas = (opt.b1, opt.b2))\n",
        "    optimizer_D_X = torch.optim.Adam(D_X.parameters(), lr = opt.lr, betas = (opt.b1, opt.b2))\n",
        "    optimizer_D_Y = torch.optim.Adam(D_Y.parameters(), lr = opt.lr, betas = (opt.b1, opt.b2))\n",
        "\n",
        "    # Learning rate update schedulers\n",
        "    LambdaLR_schedular_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda = LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
        "    LambdaLR_scheduler_D_X = torch.optim.lr_scheduler.LambdaLR(optimizer_D_X, lr_lambda = LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
        "    LambdaLR_scheduler_D_Y = torch.optim.lr_scheduler.LambdaLR(optimizer_D_Y, lr_lambda = LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
        "    \n",
        "    Tensor = torch.Tensor\n",
        "    if opt.cuda:  \n",
        "        loss_GAN.cuda()\n",
        "        loss_cycle.cuda()\n",
        "        Tensor = torch.cuda.FloatTensor\n",
        "\n",
        "    def sample_images(batches_done):\n",
        "        \"\"\"Saves a generated sample from the test set\"\"\"\n",
        "        imgs = next(iter(test_dataloader))\n",
        "        G_XtoY.eval()\n",
        "        G_YtoX.eval()\n",
        "        real_X = Variable(imgs[\"X\"].type(Tensor))\n",
        "        fake_Y = G_XtoY(real_X)\n",
        "        real_Y = Variable(imgs[\"Y\"].type(Tensor))\n",
        "        fake_X = G_YtoX(real_Y)\n",
        "        # Arange images along x-axis\n",
        "        real_X = make_grid(real_X, nrow = 5, normalize = True)\n",
        "        real_Y = make_grid(real_Y, nrow = 5, normalize = True)\n",
        "        fake_X = make_grid(fake_X, nrow = 5, normalize = True)\n",
        "        fake_Y = make_grid(fake_Y, nrow = 5, normalize = True)\n",
        "        # Arange images along y-axis\n",
        "        image_grid = torch.cat((real_X, fake_Y, real_Y, fake_X), 1)\n",
        "        save_image(image_grid, \"images/%s.png\" % batches_done, normalize = False)\n",
        "    \n",
        "    losses_models_G = pd.DataFrame(np.zeros((len(train_dataloader), opt.n_epochs - opt.epoch + 1)))\n",
        "    losses_models_D = pd.DataFrame(np.zeros((len(train_dataloader), opt.n_epochs - opt.epoch + 1)))\n",
        "    losses_models_G.columns = range(opt.epoch, opt.n_epochs+1)\n",
        "    losses_models_D.columns = range(opt.epoch, opt.n_epochs+1)\n",
        "    # Training\n",
        "    for epoch in range(opt.epoch, opt.n_epochs):\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "            \n",
        "            # Set model input\n",
        "            real_X = Variable(batch[\"X\"].type(Tensor))\n",
        "            real_Y = Variable(batch[\"Y\"].type(Tensor))\n",
        "            \n",
        "            # Adversarial ground truths\n",
        "            valid = Variable(Tensor(np.ones((real_X.size(0), *D_X.output_shape))), requires_grad = False)\n",
        "            fake = Variable(Tensor(np.zeros((real_X.size(0), *D_X.output_shape))), requires_grad = False)\n",
        "                        \n",
        "            # -----------------------\n",
        "            #  Train Discriminator X\n",
        "            # -----------------------\n",
        "            \n",
        "            optimizer_D_X.zero_grad()\n",
        "        \n",
        "            # Real loss\n",
        "            loss_real_D_X = loss_GAN(D_X(real_X), valid)\n",
        "            \n",
        "            # Fake loss\n",
        "            fake_X = G_YtoX(real_Y)\n",
        "            loss_fake_D_X = loss_GAN(D_X(fake_X), fake)\n",
        "            \n",
        "            # Total loss\n",
        "            loss_D_X = (loss_real_D_X + loss_fake_D_X) / 2\n",
        "        \n",
        "            loss_D_X.backward()\n",
        "            optimizer_D_X.step()\n",
        "            \n",
        "            # -----------------------\n",
        "            #  Train Discriminator Y\n",
        "            # -----------------------\n",
        "        \n",
        "            optimizer_D_Y.zero_grad()\n",
        "            \n",
        "            # Real loss\n",
        "            loss_real_D_Y = loss_GAN(D_Y(real_Y), valid)\n",
        "            \n",
        "            # Fake loss\n",
        "            fake_Y = G_XtoY(real_X)\n",
        "            loss_fake_D_Y = loss_GAN(D_Y(fake_Y), fake)\n",
        "            \n",
        "            # Total loss\n",
        "            loss_D_Y = (loss_real_D_Y + loss_fake_D_Y) / 2\n",
        "        \n",
        "            loss_D_Y.backward()\n",
        "            optimizer_D_Y.step()\n",
        "        \n",
        "            loss_D = (loss_D_X + loss_D_Y) / 2\n",
        "            losses_models_D[epoch][i] = loss_D\n",
        "            \n",
        "            # ------------------------------\n",
        "            #  Train Generators XtoY and YtoX\n",
        "            # -------------------------------\n",
        "            \n",
        "            G_XtoY.train()\n",
        "            G_YtoX.train()\n",
        "            \n",
        "            optimizer_G.zero_grad()\n",
        "            \n",
        "            # GAN loss\n",
        "            fake_Y = G_XtoY(real_X)\n",
        "            loss_GAN_XtoY = loss_GAN(D_Y(fake_Y), valid)\n",
        "            fake_X = G_YtoX(real_Y)\n",
        "            loss_GAN_YtoX = loss_GAN(D_X(fake_X), valid)\n",
        "            loss_GAN_G = (loss_GAN_XtoY + loss_GAN_YtoX) / 2\n",
        "            \n",
        "            # Cycle loss\n",
        "            recov_X = G_YtoX(fake_Y)\n",
        "            loss_cycle_X = loss_cycle(recov_X, real_X)\n",
        "            recov_Y = G_XtoY(fake_X)\n",
        "            loss_cycle_Y = loss_cycle(recov_Y, real_Y)\n",
        "            loss_cycle_G = (loss_cycle_X + loss_cycle_Y) / 2\n",
        "            \n",
        "            # Identity loss\n",
        "            loss_identity_X = loss_identity(G_YtoX(real_X), real_X)\n",
        "            loss_identity_Y = loss_identity(G_XtoY(real_Y), real_Y)\n",
        "            loss_identity_G = (loss_identity_X + loss_identity_Y) / 2\n",
        "            \n",
        "            # Total loss\n",
        "            loss_G = loss_GAN_G + opt.lambda_cyc * loss_cycle_G\n",
        "            \n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "            losses_models_G[epoch][i] = loss_G\n",
        "        \n",
        "            # --------------\n",
        "            #  Log Progress\n",
        "            # --------------\n",
        "        \n",
        "            batches_done = epoch * len(train_dataloader) + i\n",
        "        \n",
        "            # Print log\n",
        "            sys.stdout.write(\n",
        "                \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "                % (\n",
        "                    epoch,\n",
        "                    opt.n_epochs,\n",
        "                    i,\n",
        "                    len(train_dataloader),\n",
        "                    loss_D.item(),\n",
        "                    loss_G.item()\n",
        "                )\n",
        "            )\n",
        "        \n",
        "            # Save sample image at interval\n",
        "            if batches_done % opt.sample_interval == 0:\n",
        "                sample_images(batches_done)\n",
        "        \n",
        "        # Update learning rates\n",
        "        LambdaLR_schedular_G.step()\n",
        "        LambdaLR_scheduler_D_X.step()\n",
        "        LambdaLR_scheduler_D_Y.step()\n",
        "        \n",
        "        # Save discriminators and generators lossses at each epoch\n",
        "        losses_models_G.to_pickle(\"losses_models/losses_models_G_%d\" % epoch)\n",
        "        losses_models_D.to_pickle(\"losses_models/losses_models_D_%d\" % epoch)\n",
        "            \n",
        "        # Save model at checkpoints\n",
        "        if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n",
        "            torch.save(G_XtoY.state_dict(), \"saved_models/G_XtoY_%d.pth\" % epoch)\n",
        "            torch.save(G_YtoX.state_dict(), \"saved_models/G_YtoX_%d.pth\" % epoch)\n",
        "            torch.save(D_X.state_dict(), \"saved_models/D_X_%d.pth\" % epoch)\n",
        "            torch.save(D_Y.state_dict(), \"saved_models/D_Y_%d.pth\" % epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Models moved to GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziUfqW6N69Ex",
        "colab_type": "code",
        "outputId": "d56be7e4-905e-4f75-d2ea-427547a63219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "training_loop(train_dataloader, test_dataloader, opt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 G_XtoY                \n",
            "---------------------------------------\n",
            "Generator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (11): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (12): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (13): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (14): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (15): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (16): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (20): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (24): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (28): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (29): Tanh()\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                 G_YtoX                \n",
            "---------------------------------------\n",
            "Generator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (11): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (12): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (13): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (14): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (15): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (16): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (20): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (24): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (28): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (29): Tanh()\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_X                  \n",
            "---------------------------------------\n",
            "Discriminator(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
            "    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "                  D_Y                  \n",
            "---------------------------------------\n",
            "Discriminator(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
            "    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n",
            "---------------------------------------\n",
            "[Epoch 13/50] [Batch 587/1875] [D loss: 0.250000] [G loss: 0.621749]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-cb150a924d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-7d385fb7344a>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(train_dataloader, test_dataloader, opt)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mloss_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_D_X\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_D_Y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mlosses_models_D\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m              \u001b[0;31m# ------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_with_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSettingWithCopyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_set_with_engine\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}